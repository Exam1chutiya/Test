<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Exam Answers – Big Data</title>

<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        background: #f4f7fa;
        line-height: 1.6;
    }
    .container {
        max-width: 1200px;
        margin: auto;
        padding: 20px;
        background: #fff;
    }
    h1, h2, h3 {
        color: #2d4a72;
    }
    .answer-block {
        background: #fafafa;
        border-left: 5px solid #2d4a72;
        padding: 15px;
        margin-bottom: 25px;
        border-radius: 4px;
    }
    @media(max-width: 768px) {
        body { font-size: 16px; }
        .answer-block { padding: 12px; }
    }
</style>
</head>

<body>

<div class="container">
    <h1>Exam Answers – Full Detailed Solutions</h1>

    <!-- SECTION A -->
    <h2>SECTION A</h2>

    <div class="answer-block">
        <h3>Answer A1</h3>
        <p>
            The Big Data characteristic that represents <strong>correctness</strong> is 
            <strong>Veracity</strong>. Veracity indicates the accuracy, reliability,
            and trustworthiness of data. High-veracity data ensures error-free analysis and
            dependable decision-making.
        </p>
    </div>

    <div class="answer-block">
        <h3>Answer A2</h3>
        <p>
            <strong>False.</strong><br>
            In Hadoop HDFS:  
            - The <strong>NameNode</strong> stores metadata.  
            - The <strong>DataNodes</strong> store actual data blocks.
        </p>
    </div>

    <div class="answer-block">
        <h3>Answer A3</h3>
        <p>
            <strong>A – 3, B – 1, C – 2</strong><br><br>
            - A. BASE → Soft-state characteristics in NoSQL systems<br>
            - B. CQL → Cassandra Query Language<br>
            - C. CAP Theorem → Consistency, Availability, Partition Tolerance
        </p>
    </div>

    <div class="answer-block">
        <h3>Answer A4</h3>
        <p>
            <strong>NewSQL</strong> is a modern class of databases that use SQL but scale horizontally 
            like NoSQL systems while still maintaining ACID consistency. <br><br>
            <strong>Examples:</strong> Google Spanner, VoltDB, MemSQL (SingleStore), CockroachDB.
        </p>
    </div>

    <div class="answer-block">
        <h3>Answer A5</h3>
        <p>
            The <strong>Reducer</strong> in MapReduce performs aggregation, grouping,
            summarization, and filtering based on the intermediate key-value pairs generated by the Mappers.
            It produces the final output data stored in HDFS.
        </p>
    </div>

    <!-- SECTION B -->
    <h2>SECTION B</h2>

    <div class="answer-block">
        <h3>Answer B1</h3>
        <p>
            <strong>Volume:</strong> Represents the huge quantity of data generated from devices,
            sensors, logs, transactions, social media, etc., reaching terabytes to petabytes.<br><br>

            <strong>Variety:</strong> Big Data appears in structured, semi-structured, and
            unstructured formats such as text, images, audio, JSON, XML, etc.<br><br>

            <strong>Velocity:</strong> The rapid speed at which data is generated and processed.
            Examples include stock markets, online transactions, and IoT sensor streams.<br><br>

            <strong>Impact of Volume on Processing:</strong><br>
            - Requires distributed storage (HDFS)<br>
            - Needs batch/parallel processing (MapReduce/Spark)<br>
            - Compression and replication strategies become mandatory<br>
            - Traditional systems cannot handle huge volumes efficiently
        </p>
    </div>

    <div class="answer-block">
        <h3>Answer B2</h3>
        <p>
            <strong>HDFS Components:</strong><br>
            - <strong>NameNode:</strong> Stores metadata<br>
            - <strong>DataNodes:</strong> Store actual blocks<br>
            - <strong>Secondary NameNode:</strong> Merges edit logs with fsimage<br>
            - <strong>Client:</strong> Requests read/write operations<br><br>

            <strong>File Writing Steps:</strong><br>
            1. Client requests file write from NameNode.<br>
            2. NameNode responds with DataNode block locations.<br>
            3. File is split into fixed-size blocks.<br>
            4. Client writes the first block to the assigned DataNode.<br>
            5. DataNode pipelines block to other replicas.<br>
            6. Acknowledgements flow back to the client.<br>
            7. NameNode updates metadata after successful write.
        </p>
    </div>

    <div class="answer-block">
        <h3>Answer B3</h3>
        <p>
            <strong>SQL Databases:</strong><br>
            - Structured, relational, table-based<br>
            - ACID compliant<br>
            - Examples: MySQL, PostgreSQL, Oracle<br><br>

            <strong>NoSQL Databases:</strong><br>
            - Schema-free, distributed<br>
            - BASE properties<br>
            - Examples: MongoDB, Cassandra, HBase<br><br>

            <strong>NewSQL Databases:</strong><br>
            - SQL querying + horizontal scalability<br>
            - ACID guarantees<br>
            - Examples: Google Spanner, CockroachDB, VoltDB
        </p>
    </div>

    <!-- SECTION C -->
    <h2>SECTION C</h2>

    <div class="answer-block">
        <h3>Answer C1</h3>
        <p>
            <strong>Combiner:</strong><br>
            A mini-reducer run on mapper output to perform local aggregation,
            reducing data transfer to reducers.<br><br>

            <strong>Partitioner:</strong><br>
            Determines how the intermediate key-value pairs are distributed to reducers.
            Default: HashPartitioner (key.hash % numReducers).
        </p>
    </div>

    <div class="answer-block">
        <h3>Answer C2</h3>
        <p>
            <strong>Data Structure:</strong><br>
            - <strong>RDBMS:</strong> Strict schema, structured tables (schema-on-write)<br>
            - <strong>Hadoop:</strong> Supports unstructured, semi-structured data (schema-on-read)<br><br>

            <strong>Scalability:</strong><br>
            - <strong>RDBMS:</strong> Vertical scaling only<br>
            - <strong>Hadoop:</strong> Horizontal scaling across commodity machines
        </p>
    </div>

    <!-- SECTION D -->
    <h2>SECTION D</h2>

    <div class="answer-block">
        <h3>Answer D1</h3>
        <p>
            <strong>Features of MongoDB:</strong><br>
            1. Schema-less JSON-like document storage<br>
            2. High scalability using sharding and replication<br><br>

            <strong>Data Types:</strong> String, Integer, Boolean, Array, Double, ObjectId, Embedded Documents<br><br>

            <strong>Collections:</strong><br>
            Schema-free grouping of documents, similar to tables in SQL but more flexible.<br><br>

            <strong>Read Operations:</strong><br>
            - <code>find()</code><br>
            - <code>findOne()</code><br>
            - Filtering, sorting, projections, limits
        </p>
    </div>

    <div class="answer-block">
        <h3>Answer D2</h3>
        <p>
            <strong>Hive Programming Model:</strong><br>
            - SQL-like HiveQL for easy querying<br>
            - Converts queries into MapReduce/Spark/Tez jobs<br>
            - Makes Hadoop accessible to non-programmers<br><br>

            <strong>File Formats:</strong><br>
            - Text, ORC, Parquet, Avro<br>
            - ORC/Parquet provide compression, indexing, and fast read performance<br><br>

            Hive is excellent for ETL, analytical queries, and warehouse-style batch processing on Big Data.
        </p>
    </div>

</div>

</body>
</html>
